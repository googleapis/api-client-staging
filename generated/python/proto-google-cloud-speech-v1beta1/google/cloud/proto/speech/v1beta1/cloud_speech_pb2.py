# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/cloud/proto/speech/v1beta1/cloud_speech.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from google.longrunning import operations_pb2 as google_dot_longrunning_dot_operations__pb2
from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
from google.rpc import status_pb2 as google_dot_rpc_dot_status__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='google/cloud/proto/speech/v1beta1/cloud_speech.proto',
  package='google.cloud.speech.v1beta1',
  syntax='proto3',
  serialized_pb=_b('\n4google/cloud/proto/speech/v1beta1/cloud_speech.proto\x12\x1bgoogle.cloud.speech.v1beta1\x1a\x1cgoogle/api/annotations.proto\x1a#google/longrunning/operations.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x17google/rpc/status.proto\"\x94\x01\n\x14SyncRecognizeRequest\x12>\n\x06\x63onfig\x18\x01 \x01(\x0b\x32..google.cloud.speech.v1beta1.RecognitionConfig\x12<\n\x05\x61udio\x18\x02 \x01(\x0b\x32-.google.cloud.speech.v1beta1.RecognitionAudio\"\x95\x01\n\x15\x41syncRecognizeRequest\x12>\n\x06\x63onfig\x18\x01 \x01(\x0b\x32..google.cloud.speech.v1beta1.RecognitionConfig\x12<\n\x05\x61udio\x18\x02 \x01(\x0b\x32-.google.cloud.speech.v1beta1.RecognitionAudio\"\x9e\x01\n\x19StreamingRecognizeRequest\x12S\n\x10streaming_config\x18\x01 \x01(\x0b\x32\x37.google.cloud.speech.v1beta1.StreamingRecognitionConfigH\x00\x12\x17\n\raudio_content\x18\x02 \x01(\x0cH\x00\x42\x13\n\x11streaming_request\"\x8f\x01\n\x1aStreamingRecognitionConfig\x12>\n\x06\x63onfig\x18\x01 \x01(\x0b\x32..google.cloud.speech.v1beta1.RecognitionConfig\x12\x18\n\x10single_utterance\x18\x02 \x01(\x08\x12\x17\n\x0finterim_results\x18\x03 \x01(\x08\"\xea\x02\n\x11RecognitionConfig\x12N\n\x08\x65ncoding\x18\x01 \x01(\x0e\x32<.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding\x12\x13\n\x0bsample_rate\x18\x02 \x01(\x05\x12\x15\n\rlanguage_code\x18\x03 \x01(\t\x12\x18\n\x10max_alternatives\x18\x04 \x01(\x05\x12\x18\n\x10profanity_filter\x18\x05 \x01(\x08\x12\x42\n\x0espeech_context\x18\x06 \x01(\x0b\x32*.google.cloud.speech.v1beta1.SpeechContext\"a\n\rAudioEncoding\x12\x18\n\x14\x45NCODING_UNSPECIFIED\x10\x00\x12\x0c\n\x08LINEAR16\x10\x01\x12\x08\n\x04\x46LAC\x10\x02\x12\t\n\x05MULAW\x10\x03\x12\x07\n\x03\x41MR\x10\x04\x12\n\n\x06\x41MR_WB\x10\x05\" \n\rSpeechContext\x12\x0f\n\x07phrases\x18\x01 \x03(\t\"D\n\x10RecognitionAudio\x12\x11\n\x07\x63ontent\x18\x01 \x01(\x0cH\x00\x12\r\n\x03uri\x18\x02 \x01(\tH\x00\x42\x0e\n\x0c\x61udio_source\"^\n\x15SyncRecognizeResponse\x12\x45\n\x07results\x18\x02 \x03(\x0b\x32\x34.google.cloud.speech.v1beta1.SpeechRecognitionResult\"_\n\x16\x41syncRecognizeResponse\x12\x45\n\x07results\x18\x02 \x03(\x0b\x32\x34.google.cloud.speech.v1beta1.SpeechRecognitionResult\"\x98\x01\n\x16\x41syncRecognizeMetadata\x12\x18\n\x10progress_percent\x18\x01 \x01(\x05\x12.\n\nstart_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x34\n\x10last_update_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"\x85\x03\n\x1aStreamingRecognizeResponse\x12!\n\x05\x65rror\x18\x01 \x01(\x0b\x32\x12.google.rpc.Status\x12H\n\x07results\x18\x02 \x03(\x0b\x32\x37.google.cloud.speech.v1beta1.StreamingRecognitionResult\x12\x14\n\x0cresult_index\x18\x03 \x01(\x05\x12_\n\x0f\x65ndpointer_type\x18\x04 \x01(\x0e\x32\x46.google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType\"\x82\x01\n\x0e\x45ndpointerType\x12 \n\x1c\x45NDPOINTER_EVENT_UNSPECIFIED\x10\x00\x12\x13\n\x0fSTART_OF_SPEECH\x10\x01\x12\x11\n\rEND_OF_SPEECH\x10\x02\x12\x10\n\x0c\x45ND_OF_AUDIO\x10\x03\x12\x14\n\x10\x45ND_OF_UTTERANCE\x10\x04\"\x92\x01\n\x1aStreamingRecognitionResult\x12O\n\x0c\x61lternatives\x18\x01 \x03(\x0b\x32\x39.google.cloud.speech.v1beta1.SpeechRecognitionAlternative\x12\x10\n\x08is_final\x18\x02 \x01(\x08\x12\x11\n\tstability\x18\x03 \x01(\x02\"j\n\x17SpeechRecognitionResult\x12O\n\x0c\x61lternatives\x18\x01 \x03(\x0b\x32\x39.google.cloud.speech.v1beta1.SpeechRecognitionAlternative\"F\n\x1cSpeechRecognitionAlternative\x12\x12\n\ntranscript\x18\x01 \x01(\t\x12\x12\n\nconfidence\x18\x02 \x01(\x02\x32\xc8\x03\n\x06Speech\x12\xa0\x01\n\rSyncRecognize\x12\x31.google.cloud.speech.v1beta1.SyncRecognizeRequest\x1a\x32.google.cloud.speech.v1beta1.SyncRecognizeResponse\"(\x82\xd3\xe4\x93\x02\"\"\x1d/v1beta1/speech:syncrecognize:\x01*\x12\x8e\x01\n\x0e\x41syncRecognize\x12\x32.google.cloud.speech.v1beta1.AsyncRecognizeRequest\x1a\x1d.google.longrunning.Operation\")\x82\xd3\xe4\x93\x02#\"\x1e/v1beta1/speech:asyncrecognize:\x01*\x12\x89\x01\n\x12StreamingRecognize\x12\x36.google.cloud.speech.v1beta1.StreamingRecognizeRequest\x1a\x37.google.cloud.speech.v1beta1.StreamingRecognizeResponse(\x01\x30\x01\x42s\n\x1f\x63om.google.cloud.speech.v1beta1B\x0bSpeechProtoP\x01ZAgoogle.golang.org/genproto/googleapis/cloud/speech/v1beta1;speechb\x06proto3')
  ,
  dependencies=[google_dot_api_dot_annotations__pb2.DESCRIPTOR,google_dot_longrunning_dot_operations__pb2.DESCRIPTOR,google_dot_protobuf_dot_timestamp__pb2.DESCRIPTOR,google_dot_rpc_dot_status__pb2.DESCRIPTOR,])
_sym_db.RegisterFileDescriptor(DESCRIPTOR)



_RECOGNITIONCONFIG_AUDIOENCODING = _descriptor.EnumDescriptor(
  name='AudioEncoding',
  full_name='google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENCODING_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='LINEAR16', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='FLAC', index=2, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='MULAW', index=3, number=3,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='AMR', index=4, number=4,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='AMR_WB', index=5, number=5,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=1086,
  serialized_end=1183,
)
_sym_db.RegisterEnumDescriptor(_RECOGNITIONCONFIG_AUDIOENCODING)

_STREAMINGRECOGNIZERESPONSE_ENDPOINTERTYPE = _descriptor.EnumDescriptor(
  name='EndpointerType',
  full_name='google.cloud.speech.v1beta1.StreamingRecognizeResponse.EndpointerType',
  filename=None,
  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='ENDPOINTER_EVENT_UNSPECIFIED', index=0, number=0,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='START_OF_SPEECH', index=1, number=1,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='END_OF_SPEECH', index=2, number=2,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='END_OF_AUDIO', index=3, number=3,
      options=None,
      type=None),
    _descriptor.EnumValueDescriptor(
      name='END_OF_UTTERANCE', index=4, number=4,
      options=None,
      type=None),
  ],
  containing_type=None,
  options=None,
  serialized_start=1897,
  serialized_end=2027,
)
_sym_db.RegisterEnumDescriptor(_STREAMINGRECOGNIZERESPONSE_ENDPOINTERTYPE)


_SYNCRECOGNIZEREQUEST = _descriptor.Descriptor(
  name='SyncRecognizeRequest',
  full_name='google.cloud.speech.v1beta1.SyncRecognizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='google.cloud.speech.v1beta1.SyncRecognizeRequest.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio', full_name='google.cloud.speech.v1beta1.SyncRecognizeRequest.audio', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=211,
  serialized_end=359,
)


_ASYNCRECOGNIZEREQUEST = _descriptor.Descriptor(
  name='AsyncRecognizeRequest',
  full_name='google.cloud.speech.v1beta1.AsyncRecognizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='google.cloud.speech.v1beta1.AsyncRecognizeRequest.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio', full_name='google.cloud.speech.v1beta1.AsyncRecognizeRequest.audio', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=362,
  serialized_end=511,
)


_STREAMINGRECOGNIZEREQUEST = _descriptor.Descriptor(
  name='StreamingRecognizeRequest',
  full_name='google.cloud.speech.v1beta1.StreamingRecognizeRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='streaming_config', full_name='google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='audio_content', full_name='google.cloud.speech.v1beta1.StreamingRecognizeRequest.audio_content', index=1,
      number=2, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='streaming_request', full_name='google.cloud.speech.v1beta1.StreamingRecognizeRequest.streaming_request',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=514,
  serialized_end=672,
)


_STREAMINGRECOGNITIONCONFIG = _descriptor.Descriptor(
  name='StreamingRecognitionConfig',
  full_name='google.cloud.speech.v1beta1.StreamingRecognitionConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='config', full_name='google.cloud.speech.v1beta1.StreamingRecognitionConfig.config', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='single_utterance', full_name='google.cloud.speech.v1beta1.StreamingRecognitionConfig.single_utterance', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='interim_results', full_name='google.cloud.speech.v1beta1.StreamingRecognitionConfig.interim_results', index=2,
      number=3, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=675,
  serialized_end=818,
)


_RECOGNITIONCONFIG = _descriptor.Descriptor(
  name='RecognitionConfig',
  full_name='google.cloud.speech.v1beta1.RecognitionConfig',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='encoding', full_name='google.cloud.speech.v1beta1.RecognitionConfig.encoding', index=0,
      number=1, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='sample_rate', full_name='google.cloud.speech.v1beta1.RecognitionConfig.sample_rate', index=1,
      number=2, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='language_code', full_name='google.cloud.speech.v1beta1.RecognitionConfig.language_code', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='max_alternatives', full_name='google.cloud.speech.v1beta1.RecognitionConfig.max_alternatives', index=3,
      number=4, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='profanity_filter', full_name='google.cloud.speech.v1beta1.RecognitionConfig.profanity_filter', index=4,
      number=5, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='speech_context', full_name='google.cloud.speech.v1beta1.RecognitionConfig.speech_context', index=5,
      number=6, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _RECOGNITIONCONFIG_AUDIOENCODING,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=821,
  serialized_end=1183,
)


_SPEECHCONTEXT = _descriptor.Descriptor(
  name='SpeechContext',
  full_name='google.cloud.speech.v1beta1.SpeechContext',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='phrases', full_name='google.cloud.speech.v1beta1.SpeechContext.phrases', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1185,
  serialized_end=1217,
)


_RECOGNITIONAUDIO = _descriptor.Descriptor(
  name='RecognitionAudio',
  full_name='google.cloud.speech.v1beta1.RecognitionAudio',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='content', full_name='google.cloud.speech.v1beta1.RecognitionAudio.content', index=0,
      number=1, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=_b(""),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='uri', full_name='google.cloud.speech.v1beta1.RecognitionAudio.uri', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
    _descriptor.OneofDescriptor(
      name='audio_source', full_name='google.cloud.speech.v1beta1.RecognitionAudio.audio_source',
      index=0, containing_type=None, fields=[]),
  ],
  serialized_start=1219,
  serialized_end=1287,
)


_SYNCRECOGNIZERESPONSE = _descriptor.Descriptor(
  name='SyncRecognizeResponse',
  full_name='google.cloud.speech.v1beta1.SyncRecognizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='results', full_name='google.cloud.speech.v1beta1.SyncRecognizeResponse.results', index=0,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1289,
  serialized_end=1383,
)


_ASYNCRECOGNIZERESPONSE = _descriptor.Descriptor(
  name='AsyncRecognizeResponse',
  full_name='google.cloud.speech.v1beta1.AsyncRecognizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='results', full_name='google.cloud.speech.v1beta1.AsyncRecognizeResponse.results', index=0,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1385,
  serialized_end=1480,
)


_ASYNCRECOGNIZEMETADATA = _descriptor.Descriptor(
  name='AsyncRecognizeMetadata',
  full_name='google.cloud.speech.v1beta1.AsyncRecognizeMetadata',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='progress_percent', full_name='google.cloud.speech.v1beta1.AsyncRecognizeMetadata.progress_percent', index=0,
      number=1, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='start_time', full_name='google.cloud.speech.v1beta1.AsyncRecognizeMetadata.start_time', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='last_update_time', full_name='google.cloud.speech.v1beta1.AsyncRecognizeMetadata.last_update_time', index=2,
      number=3, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1483,
  serialized_end=1635,
)


_STREAMINGRECOGNIZERESPONSE = _descriptor.Descriptor(
  name='StreamingRecognizeResponse',
  full_name='google.cloud.speech.v1beta1.StreamingRecognizeResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='error', full_name='google.cloud.speech.v1beta1.StreamingRecognizeResponse.error', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='results', full_name='google.cloud.speech.v1beta1.StreamingRecognizeResponse.results', index=1,
      number=2, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='result_index', full_name='google.cloud.speech.v1beta1.StreamingRecognizeResponse.result_index', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='endpointer_type', full_name='google.cloud.speech.v1beta1.StreamingRecognizeResponse.endpointer_type', index=3,
      number=4, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
    _STREAMINGRECOGNIZERESPONSE_ENDPOINTERTYPE,
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=1638,
  serialized_end=2027,
)


_STREAMINGRECOGNITIONRESULT = _descriptor.Descriptor(
  name='StreamingRecognitionResult',
  full_name='google.cloud.speech.v1beta1.StreamingRecognitionResult',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='alternatives', full_name='google.cloud.speech.v1beta1.StreamingRecognitionResult.alternatives', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='is_final', full_name='google.cloud.speech.v1beta1.StreamingRecognitionResult.is_final', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='stability', full_name='google.cloud.speech.v1beta1.StreamingRecognitionResult.stability', index=2,
      number=3, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2030,
  serialized_end=2176,
)


_SPEECHRECOGNITIONRESULT = _descriptor.Descriptor(
  name='SpeechRecognitionResult',
  full_name='google.cloud.speech.v1beta1.SpeechRecognitionResult',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='alternatives', full_name='google.cloud.speech.v1beta1.SpeechRecognitionResult.alternatives', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2178,
  serialized_end=2284,
)


_SPEECHRECOGNITIONALTERNATIVE = _descriptor.Descriptor(
  name='SpeechRecognitionAlternative',
  full_name='google.cloud.speech.v1beta1.SpeechRecognitionAlternative',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='transcript', full_name='google.cloud.speech.v1beta1.SpeechRecognitionAlternative.transcript', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
    _descriptor.FieldDescriptor(
      name='confidence', full_name='google.cloud.speech.v1beta1.SpeechRecognitionAlternative.confidence', index=1,
      number=2, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=2286,
  serialized_end=2356,
)

_SYNCRECOGNIZEREQUEST.fields_by_name['config'].message_type = _RECOGNITIONCONFIG
_SYNCRECOGNIZEREQUEST.fields_by_name['audio'].message_type = _RECOGNITIONAUDIO
_ASYNCRECOGNIZEREQUEST.fields_by_name['config'].message_type = _RECOGNITIONCONFIG
_ASYNCRECOGNIZEREQUEST.fields_by_name['audio'].message_type = _RECOGNITIONAUDIO
_STREAMINGRECOGNIZEREQUEST.fields_by_name['streaming_config'].message_type = _STREAMINGRECOGNITIONCONFIG
_STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request'].fields.append(
  _STREAMINGRECOGNIZEREQUEST.fields_by_name['streaming_config'])
_STREAMINGRECOGNIZEREQUEST.fields_by_name['streaming_config'].containing_oneof = _STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request']
_STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request'].fields.append(
  _STREAMINGRECOGNIZEREQUEST.fields_by_name['audio_content'])
_STREAMINGRECOGNIZEREQUEST.fields_by_name['audio_content'].containing_oneof = _STREAMINGRECOGNIZEREQUEST.oneofs_by_name['streaming_request']
_STREAMINGRECOGNITIONCONFIG.fields_by_name['config'].message_type = _RECOGNITIONCONFIG
_RECOGNITIONCONFIG.fields_by_name['encoding'].enum_type = _RECOGNITIONCONFIG_AUDIOENCODING
_RECOGNITIONCONFIG.fields_by_name['speech_context'].message_type = _SPEECHCONTEXT
_RECOGNITIONCONFIG_AUDIOENCODING.containing_type = _RECOGNITIONCONFIG
_RECOGNITIONAUDIO.oneofs_by_name['audio_source'].fields.append(
  _RECOGNITIONAUDIO.fields_by_name['content'])
_RECOGNITIONAUDIO.fields_by_name['content'].containing_oneof = _RECOGNITIONAUDIO.oneofs_by_name['audio_source']
_RECOGNITIONAUDIO.oneofs_by_name['audio_source'].fields.append(
  _RECOGNITIONAUDIO.fields_by_name['uri'])
_RECOGNITIONAUDIO.fields_by_name['uri'].containing_oneof = _RECOGNITIONAUDIO.oneofs_by_name['audio_source']
_SYNCRECOGNIZERESPONSE.fields_by_name['results'].message_type = _SPEECHRECOGNITIONRESULT
_ASYNCRECOGNIZERESPONSE.fields_by_name['results'].message_type = _SPEECHRECOGNITIONRESULT
_ASYNCRECOGNIZEMETADATA.fields_by_name['start_time'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP
_ASYNCRECOGNIZEMETADATA.fields_by_name['last_update_time'].message_type = google_dot_protobuf_dot_timestamp__pb2._TIMESTAMP
_STREAMINGRECOGNIZERESPONSE.fields_by_name['error'].message_type = google_dot_rpc_dot_status__pb2._STATUS
_STREAMINGRECOGNIZERESPONSE.fields_by_name['results'].message_type = _STREAMINGRECOGNITIONRESULT
_STREAMINGRECOGNIZERESPONSE.fields_by_name['endpointer_type'].enum_type = _STREAMINGRECOGNIZERESPONSE_ENDPOINTERTYPE
_STREAMINGRECOGNIZERESPONSE_ENDPOINTERTYPE.containing_type = _STREAMINGRECOGNIZERESPONSE
_STREAMINGRECOGNITIONRESULT.fields_by_name['alternatives'].message_type = _SPEECHRECOGNITIONALTERNATIVE
_SPEECHRECOGNITIONRESULT.fields_by_name['alternatives'].message_type = _SPEECHRECOGNITIONALTERNATIVE
DESCRIPTOR.message_types_by_name['SyncRecognizeRequest'] = _SYNCRECOGNIZEREQUEST
DESCRIPTOR.message_types_by_name['AsyncRecognizeRequest'] = _ASYNCRECOGNIZEREQUEST
DESCRIPTOR.message_types_by_name['StreamingRecognizeRequest'] = _STREAMINGRECOGNIZEREQUEST
DESCRIPTOR.message_types_by_name['StreamingRecognitionConfig'] = _STREAMINGRECOGNITIONCONFIG
DESCRIPTOR.message_types_by_name['RecognitionConfig'] = _RECOGNITIONCONFIG
DESCRIPTOR.message_types_by_name['SpeechContext'] = _SPEECHCONTEXT
DESCRIPTOR.message_types_by_name['RecognitionAudio'] = _RECOGNITIONAUDIO
DESCRIPTOR.message_types_by_name['SyncRecognizeResponse'] = _SYNCRECOGNIZERESPONSE
DESCRIPTOR.message_types_by_name['AsyncRecognizeResponse'] = _ASYNCRECOGNIZERESPONSE
DESCRIPTOR.message_types_by_name['AsyncRecognizeMetadata'] = _ASYNCRECOGNIZEMETADATA
DESCRIPTOR.message_types_by_name['StreamingRecognizeResponse'] = _STREAMINGRECOGNIZERESPONSE
DESCRIPTOR.message_types_by_name['StreamingRecognitionResult'] = _STREAMINGRECOGNITIONRESULT
DESCRIPTOR.message_types_by_name['SpeechRecognitionResult'] = _SPEECHRECOGNITIONRESULT
DESCRIPTOR.message_types_by_name['SpeechRecognitionAlternative'] = _SPEECHRECOGNITIONALTERNATIVE

SyncRecognizeRequest = _reflection.GeneratedProtocolMessageType('SyncRecognizeRequest', (_message.Message,), dict(
  DESCRIPTOR = _SYNCRECOGNIZEREQUEST,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SyncRecognizeRequest)
  ))
_sym_db.RegisterMessage(SyncRecognizeRequest)

AsyncRecognizeRequest = _reflection.GeneratedProtocolMessageType('AsyncRecognizeRequest', (_message.Message,), dict(
  DESCRIPTOR = _ASYNCRECOGNIZEREQUEST,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeRequest)
  ))
_sym_db.RegisterMessage(AsyncRecognizeRequest)

StreamingRecognizeRequest = _reflection.GeneratedProtocolMessageType('StreamingRecognizeRequest', (_message.Message,), dict(
  DESCRIPTOR = _STREAMINGRECOGNIZEREQUEST,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognizeRequest)
  ))
_sym_db.RegisterMessage(StreamingRecognizeRequest)

StreamingRecognitionConfig = _reflection.GeneratedProtocolMessageType('StreamingRecognitionConfig', (_message.Message,), dict(
  DESCRIPTOR = _STREAMINGRECOGNITIONCONFIG,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognitionConfig)
  ))
_sym_db.RegisterMessage(StreamingRecognitionConfig)

RecognitionConfig = _reflection.GeneratedProtocolMessageType('RecognitionConfig', (_message.Message,), dict(
  DESCRIPTOR = _RECOGNITIONCONFIG,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionConfig)
  ))
_sym_db.RegisterMessage(RecognitionConfig)

SpeechContext = _reflection.GeneratedProtocolMessageType('SpeechContext', (_message.Message,), dict(
  DESCRIPTOR = _SPEECHCONTEXT,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechContext)
  ))
_sym_db.RegisterMessage(SpeechContext)

RecognitionAudio = _reflection.GeneratedProtocolMessageType('RecognitionAudio', (_message.Message,), dict(
  DESCRIPTOR = _RECOGNITIONAUDIO,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionAudio)
  ))
_sym_db.RegisterMessage(RecognitionAudio)

SyncRecognizeResponse = _reflection.GeneratedProtocolMessageType('SyncRecognizeResponse', (_message.Message,), dict(
  DESCRIPTOR = _SYNCRECOGNIZERESPONSE,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SyncRecognizeResponse)
  ))
_sym_db.RegisterMessage(SyncRecognizeResponse)

AsyncRecognizeResponse = _reflection.GeneratedProtocolMessageType('AsyncRecognizeResponse', (_message.Message,), dict(
  DESCRIPTOR = _ASYNCRECOGNIZERESPONSE,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeResponse)
  ))
_sym_db.RegisterMessage(AsyncRecognizeResponse)

AsyncRecognizeMetadata = _reflection.GeneratedProtocolMessageType('AsyncRecognizeMetadata', (_message.Message,), dict(
  DESCRIPTOR = _ASYNCRECOGNIZEMETADATA,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.AsyncRecognizeMetadata)
  ))
_sym_db.RegisterMessage(AsyncRecognizeMetadata)

StreamingRecognizeResponse = _reflection.GeneratedProtocolMessageType('StreamingRecognizeResponse', (_message.Message,), dict(
  DESCRIPTOR = _STREAMINGRECOGNIZERESPONSE,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognizeResponse)
  ))
_sym_db.RegisterMessage(StreamingRecognizeResponse)

StreamingRecognitionResult = _reflection.GeneratedProtocolMessageType('StreamingRecognitionResult', (_message.Message,), dict(
  DESCRIPTOR = _STREAMINGRECOGNITIONRESULT,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.StreamingRecognitionResult)
  ))
_sym_db.RegisterMessage(StreamingRecognitionResult)

SpeechRecognitionResult = _reflection.GeneratedProtocolMessageType('SpeechRecognitionResult', (_message.Message,), dict(
  DESCRIPTOR = _SPEECHRECOGNITIONRESULT,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechRecognitionResult)
  ))
_sym_db.RegisterMessage(SpeechRecognitionResult)

SpeechRecognitionAlternative = _reflection.GeneratedProtocolMessageType('SpeechRecognitionAlternative', (_message.Message,), dict(
  DESCRIPTOR = _SPEECHRECOGNITIONALTERNATIVE,
  __module__ = 'google.cloud.proto.speech.v1beta1.cloud_speech_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.SpeechRecognitionAlternative)
  ))
_sym_db.RegisterMessage(SpeechRecognitionAlternative)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n\037com.google.cloud.speech.v1beta1B\013SpeechProtoP\001ZAgoogle.golang.org/genproto/googleapis/cloud/speech/v1beta1;speech'))
try:
  # THESE ELEMENTS WILL BE DEPRECATED.
  # Please use the generated *_pb2_grpc.py files instead.
  import grpc
  from grpc.framework.common import cardinality
  from grpc.framework.interfaces.face import utilities as face_utilities
  from grpc.beta import implementations as beta_implementations
  from grpc.beta import interfaces as beta_interfaces


  class SpeechStub(object):
    """Service that implements Google Cloud Speech API.
    """

    def __init__(self, channel):
      """Constructor.

      Args:
        channel: A grpc.Channel.
      """
      self.SyncRecognize = channel.unary_unary(
          '/google.cloud.speech.v1beta1.Speech/SyncRecognize',
          request_serializer=SyncRecognizeRequest.SerializeToString,
          response_deserializer=SyncRecognizeResponse.FromString,
          )
      self.AsyncRecognize = channel.unary_unary(
          '/google.cloud.speech.v1beta1.Speech/AsyncRecognize',
          request_serializer=AsyncRecognizeRequest.SerializeToString,
          response_deserializer=google_dot_longrunning_dot_operations__pb2.Operation.FromString,
          )
      self.StreamingRecognize = channel.stream_stream(
          '/google.cloud.speech.v1beta1.Speech/StreamingRecognize',
          request_serializer=StreamingRecognizeRequest.SerializeToString,
          response_deserializer=StreamingRecognizeResponse.FromString,
          )


  class SpeechServicer(object):
    """Service that implements Google Cloud Speech API.
    """

    def SyncRecognize(self, request, context):
      """Perform synchronous speech-recognition: receive results after all audio
      has been sent and processed.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def AsyncRecognize(self, request, context):
      """Perform asynchronous speech-recognition: receive results via the
      google.longrunning.Operations interface. Returns either an
      `Operation.error` or an `Operation.response` which contains
      an `AsyncRecognizeResponse` message.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')

    def StreamingRecognize(self, request_iterator, context):
      """Perform bidirectional streaming speech-recognition: receive results while
      sending audio. This method is only available via the gRPC API (not REST).
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')


  def add_SpeechServicer_to_server(servicer, server):
    rpc_method_handlers = {
        'SyncRecognize': grpc.unary_unary_rpc_method_handler(
            servicer.SyncRecognize,
            request_deserializer=SyncRecognizeRequest.FromString,
            response_serializer=SyncRecognizeResponse.SerializeToString,
        ),
        'AsyncRecognize': grpc.unary_unary_rpc_method_handler(
            servicer.AsyncRecognize,
            request_deserializer=AsyncRecognizeRequest.FromString,
            response_serializer=google_dot_longrunning_dot_operations__pb2.Operation.SerializeToString,
        ),
        'StreamingRecognize': grpc.stream_stream_rpc_method_handler(
            servicer.StreamingRecognize,
            request_deserializer=StreamingRecognizeRequest.FromString,
            response_serializer=StreamingRecognizeResponse.SerializeToString,
        ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
        'google.cloud.speech.v1beta1.Speech', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


  class BetaSpeechServicer(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """Service that implements Google Cloud Speech API.
    """
    def SyncRecognize(self, request, context):
      """Perform synchronous speech-recognition: receive results after all audio
      has been sent and processed.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def AsyncRecognize(self, request, context):
      """Perform asynchronous speech-recognition: receive results via the
      google.longrunning.Operations interface. Returns either an
      `Operation.error` or an `Operation.response` which contains
      an `AsyncRecognizeResponse` message.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
    def StreamingRecognize(self, request_iterator, context):
      """Perform bidirectional streaming speech-recognition: receive results while
      sending audio. This method is only available via the gRPC API (not REST).
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


  class BetaSpeechStub(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """Service that implements Google Cloud Speech API.
    """
    def SyncRecognize(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Perform synchronous speech-recognition: receive results after all audio
      has been sent and processed.
      """
      raise NotImplementedError()
    SyncRecognize.future = None
    def AsyncRecognize(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """Perform asynchronous speech-recognition: receive results via the
      google.longrunning.Operations interface. Returns either an
      `Operation.error` or an `Operation.response` which contains
      an `AsyncRecognizeResponse` message.
      """
      raise NotImplementedError()
    AsyncRecognize.future = None
    def StreamingRecognize(self, request_iterator, timeout, metadata=None, with_call=False, protocol_options=None):
      """Perform bidirectional streaming speech-recognition: receive results while
      sending audio. This method is only available via the gRPC API (not REST).
      """
      raise NotImplementedError()


  def beta_create_Speech_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_deserializers = {
      ('google.cloud.speech.v1beta1.Speech', 'AsyncRecognize'): AsyncRecognizeRequest.FromString,
      ('google.cloud.speech.v1beta1.Speech', 'StreamingRecognize'): StreamingRecognizeRequest.FromString,
      ('google.cloud.speech.v1beta1.Speech', 'SyncRecognize'): SyncRecognizeRequest.FromString,
    }
    response_serializers = {
      ('google.cloud.speech.v1beta1.Speech', 'AsyncRecognize'): google_dot_longrunning_dot_operations__pb2.Operation.SerializeToString,
      ('google.cloud.speech.v1beta1.Speech', 'StreamingRecognize'): StreamingRecognizeResponse.SerializeToString,
      ('google.cloud.speech.v1beta1.Speech', 'SyncRecognize'): SyncRecognizeResponse.SerializeToString,
    }
    method_implementations = {
      ('google.cloud.speech.v1beta1.Speech', 'AsyncRecognize'): face_utilities.unary_unary_inline(servicer.AsyncRecognize),
      ('google.cloud.speech.v1beta1.Speech', 'StreamingRecognize'): face_utilities.stream_stream_inline(servicer.StreamingRecognize),
      ('google.cloud.speech.v1beta1.Speech', 'SyncRecognize'): face_utilities.unary_unary_inline(servicer.SyncRecognize),
    }
    server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
    return beta_implementations.server(method_implementations, options=server_options)


  def beta_create_Speech_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_serializers = {
      ('google.cloud.speech.v1beta1.Speech', 'AsyncRecognize'): AsyncRecognizeRequest.SerializeToString,
      ('google.cloud.speech.v1beta1.Speech', 'StreamingRecognize'): StreamingRecognizeRequest.SerializeToString,
      ('google.cloud.speech.v1beta1.Speech', 'SyncRecognize'): SyncRecognizeRequest.SerializeToString,
    }
    response_deserializers = {
      ('google.cloud.speech.v1beta1.Speech', 'AsyncRecognize'): google_dot_longrunning_dot_operations__pb2.Operation.FromString,
      ('google.cloud.speech.v1beta1.Speech', 'StreamingRecognize'): StreamingRecognizeResponse.FromString,
      ('google.cloud.speech.v1beta1.Speech', 'SyncRecognize'): SyncRecognizeResponse.FromString,
    }
    cardinalities = {
      'AsyncRecognize': cardinality.Cardinality.UNARY_UNARY,
      'StreamingRecognize': cardinality.Cardinality.STREAM_STREAM,
      'SyncRecognize': cardinality.Cardinality.UNARY_UNARY,
    }
    stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
    return beta_implementations.dynamic_stub(channel, 'google.cloud.speech.v1beta1.Speech', cardinalities, options=stub_options)
except ImportError:
  pass
# @@protoc_insertion_point(module_scope)
