// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/bigtable/v2/bigtable.proto

package com.google.bigtable.v2;

public interface ReadRowsResponseOrBuilder extends
    // @@protoc_insertion_point(interface_extends:google.bigtable.v2.ReadRowsResponse)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <code>repeated .google.bigtable.v2.ReadRowsResponse.CellChunk chunks = 1;</code>
   */
  java.util.List<com.google.bigtable.v2.ReadRowsResponse.CellChunk> 
      getChunksList();
  /**
   * <code>repeated .google.bigtable.v2.ReadRowsResponse.CellChunk chunks = 1;</code>
   */
  com.google.bigtable.v2.ReadRowsResponse.CellChunk getChunks(int index);
  /**
   * <code>repeated .google.bigtable.v2.ReadRowsResponse.CellChunk chunks = 1;</code>
   */
  int getChunksCount();
  /**
   * <code>repeated .google.bigtable.v2.ReadRowsResponse.CellChunk chunks = 1;</code>
   */
  java.util.List<? extends com.google.bigtable.v2.ReadRowsResponse.CellChunkOrBuilder> 
      getChunksOrBuilderList();
  /**
   * <code>repeated .google.bigtable.v2.ReadRowsResponse.CellChunk chunks = 1;</code>
   */
  com.google.bigtable.v2.ReadRowsResponse.CellChunkOrBuilder getChunksOrBuilder(
      int index);

  /**
   * <pre>
   * Optionally the server might return the row key of the last row it
   * has scanned.  The client can use this to construct a more
   * efficient retry request if needed: any row keys or portions of
   * ranges less than this row key can be dropped from the request.
   * This is primarily useful for cases where the server has read a
   * lot of data that was filtered out since the last committed row
   * key, allowing the client to skip that work on a retry.
   * </pre>
   *
   * <code>bytes last_scanned_row_key = 2;</code>
   */
  com.google.protobuf.ByteString getLastScannedRowKey();
}
